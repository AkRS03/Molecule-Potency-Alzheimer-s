{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Compiled_descriptors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MW', 'AMW', 'Sv', 'Mv', 'Me', 'Mp', 'Mi', 'GD', 'nTA', 'nBM',\n",
       "       ...\n",
       "       'ALOGP2', 'PDI', 'BLTF96', 'DLS_02', 'DLS_03', 'DLS_04', 'DLS_06',\n",
       "       'DLS_cons', 'LLS_01', 'LLS_02'],\n",
       "      dtype='object', length=737)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>GD</th>\n",
       "      <th>nTA</th>\n",
       "      <th>nBM</th>\n",
       "      <th>...</th>\n",
       "      <th>PDI</th>\n",
       "      <th>BLTF96</th>\n",
       "      <th>DLS_02</th>\n",
       "      <th>DLS_03</th>\n",
       "      <th>DLS_04</th>\n",
       "      <th>DLS_06</th>\n",
       "      <th>DLS_cons</th>\n",
       "      <th>LLS_01</th>\n",
       "      <th>LLS_02</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>359.4</td>\n",
       "      <td>8.357</td>\n",
       "      <td>28.24</td>\n",
       "      <td>0.657</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1.123</td>\n",
       "      <td>0.083</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368.4</td>\n",
       "      <td>7.839</td>\n",
       "      <td>30.56</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.115</td>\n",
       "      <td>0.080</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>370.5</td>\n",
       "      <td>6.501</td>\n",
       "      <td>33.76</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.124</td>\n",
       "      <td>0.080</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>-5.32</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249.3</td>\n",
       "      <td>7.334</td>\n",
       "      <td>22.23</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.694</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018</td>\n",
       "      <td>-4.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269.8</td>\n",
       "      <td>8.702</td>\n",
       "      <td>21.53</td>\n",
       "      <td>0.694</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.732</td>\n",
       "      <td>1.113</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>304.3</td>\n",
       "      <td>8.949</td>\n",
       "      <td>23.16</td>\n",
       "      <td>0.681</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.116</td>\n",
       "      <td>0.104</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>365.6</td>\n",
       "      <td>7.947</td>\n",
       "      <td>30.42</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.729</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.093</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023</td>\n",
       "      <td>-4.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>265.4</td>\n",
       "      <td>6.805</td>\n",
       "      <td>24.28</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.123</td>\n",
       "      <td>0.116</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>292.3</td>\n",
       "      <td>8.119</td>\n",
       "      <td>21.45</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1.056</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1.155</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>198.3</td>\n",
       "      <td>6.838</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1.120</td>\n",
       "      <td>0.162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052</td>\n",
       "      <td>-3.27</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MW    AMW     Sv     Mv     Me     Mp     Mi     GD  nTA   nBM  ...  \\\n",
       "0    359.4  8.357  28.24  0.657  1.034  0.658  1.123  0.083  7.0  15.0  ...   \n",
       "1    368.4  7.839  30.56  0.650  1.017  0.667  1.115  0.080  6.0  16.0  ...   \n",
       "2    370.5  6.501  33.76  0.592  0.992  0.636  1.124  0.080  8.0  10.0  ...   \n",
       "3    249.3  7.334  22.23  0.654  0.988  0.694  1.117  0.123  0.0  17.0  ...   \n",
       "4    269.8  8.702  21.53  0.694  1.002  0.732  1.113  0.123  1.0  17.0  ...   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...  ...   ...  ...   \n",
       "564  304.3  8.949  23.16  0.681  1.047  0.669  1.116  0.104  6.0  13.0  ...   \n",
       "565  365.6  7.947  30.42  0.661  0.984  0.729  1.104  0.093  2.0  15.0  ...   \n",
       "566  265.4  6.805  24.28  0.623  0.984  0.669  1.123  0.116  4.0  16.0  ...   \n",
       "567  292.3  8.119  21.45  0.596  1.056  0.583  1.155  0.100  8.0   4.0  ...   \n",
       "568  198.3  6.838  18.20  0.628  0.983  0.675  1.120  0.162  1.0  11.0  ...   \n",
       "\n",
       "       PDI  BLTF96  DLS_02  DLS_03  DLS_04  DLS_06  DLS_cons  LLS_01  LLS_02  \\\n",
       "0    0.845   -2.11    0.83    0.83     0.7    0.67      0.61    0.17    0.88   \n",
       "1    0.880   -2.87    1.00    1.00     0.6    1.00      0.80    0.33    1.00   \n",
       "2    0.886   -5.32    0.83    1.00     1.0    1.00      0.94    0.17    0.88   \n",
       "3    1.018   -4.72    1.00    1.00     0.6    1.00      0.87    0.67    1.00   \n",
       "4    1.023   -4.95    1.00    1.00     0.6    1.00      0.76    0.83    1.00   \n",
       "..     ...     ...     ...     ...     ...     ...       ...     ...     ...   \n",
       "564  0.841   -1.32    1.00    1.00     0.4    1.00      0.77    0.33    1.00   \n",
       "565  1.023   -4.75    1.00    1.00     0.8    1.00      0.90    0.33    1.00   \n",
       "566  1.000   -3.84    1.00    1.00     0.8    1.00      0.90    1.00    1.00   \n",
       "567  0.769   -0.24    0.67    0.83     0.9    0.67      0.72    0.33    0.75   \n",
       "568  1.052   -3.27    0.67    0.83     0.8    1.00      0.83    1.00    1.00   \n",
       "\n",
       "     Class  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        2  \n",
       "4        2  \n",
       "..     ...  \n",
       "564      2  \n",
       "565      1  \n",
       "566      0  \n",
       "567      2  \n",
       "568      0  \n",
       "\n",
       "[569 rows x 738 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Class',axis=1)\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar= MinMaxScaler()\n",
    "scaled_data=scalar.fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame(scaled_data, columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Class']=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>GD</th>\n",
       "      <th>nTA</th>\n",
       "      <th>nBM</th>\n",
       "      <th>...</th>\n",
       "      <th>PDI</th>\n",
       "      <th>BLTF96</th>\n",
       "      <th>DLS_02</th>\n",
       "      <th>DLS_03</th>\n",
       "      <th>DLS_04</th>\n",
       "      <th>DLS_06</th>\n",
       "      <th>DLS_cons</th>\n",
       "      <th>LLS_01</th>\n",
       "      <th>LLS_02</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169281</td>\n",
       "      <td>0.238057</td>\n",
       "      <td>0.213939</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.297994</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.273913</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755139</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.175729</td>\n",
       "      <td>0.192233</td>\n",
       "      <td>0.231515</td>\n",
       "      <td>0.809465</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786416</td>\n",
       "      <td>0.489144</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177233</td>\n",
       "      <td>0.073868</td>\n",
       "      <td>0.255758</td>\n",
       "      <td>0.737235</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.234957</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791778</td>\n",
       "      <td>0.176245</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090408</td>\n",
       "      <td>0.147558</td>\n",
       "      <td>0.168409</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.401146</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.447826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909741</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105093</td>\n",
       "      <td>0.268577</td>\n",
       "      <td>0.163106</td>\n",
       "      <td>0.864259</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.510029</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.447826</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914209</td>\n",
       "      <td>0.223499</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.129809</td>\n",
       "      <td>0.290428</td>\n",
       "      <td>0.175455</td>\n",
       "      <td>0.848070</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751564</td>\n",
       "      <td>0.687101</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.173723</td>\n",
       "      <td>0.201787</td>\n",
       "      <td>0.230455</td>\n",
       "      <td>0.823163</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.501433</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.317391</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914209</td>\n",
       "      <td>0.249042</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.101941</td>\n",
       "      <td>0.100761</td>\n",
       "      <td>0.183939</td>\n",
       "      <td>0.775841</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893655</td>\n",
       "      <td>0.365262</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.217003</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.742217</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.083095</td>\n",
       "      <td>0.802326</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687221</td>\n",
       "      <td>0.825032</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.053872</td>\n",
       "      <td>0.103680</td>\n",
       "      <td>0.137879</td>\n",
       "      <td>0.782067</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.346705</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.617391</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940125</td>\n",
       "      <td>0.438059</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MW       AMW        Sv        Mv        Me        Mp        Mi  \\\n",
       "0    0.169281  0.238057  0.213939  0.818182  0.547170  0.297994  0.430233   \n",
       "1    0.175729  0.192233  0.231515  0.809465  0.386792  0.323782  0.337209   \n",
       "2    0.177233  0.073868  0.255758  0.737235  0.150943  0.234957  0.441860   \n",
       "3    0.090408  0.147558  0.168409  0.814446  0.113208  0.401146  0.360465   \n",
       "4    0.105093  0.268577  0.163106  0.864259  0.245283  0.510029  0.313953   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "564  0.129809  0.290428  0.175455  0.848070  0.669811  0.329513  0.348837   \n",
       "565  0.173723  0.201787  0.230455  0.823163  0.075472  0.501433  0.209302   \n",
       "566  0.101941  0.100761  0.183939  0.775841  0.075472  0.329513  0.430233   \n",
       "567  0.121212  0.217003  0.162500  0.742217  0.754717  0.083095  0.802326   \n",
       "568  0.053872  0.103680  0.137879  0.782067  0.066038  0.346705  0.395349   \n",
       "\n",
       "           GD       nTA       nBM  ...       PDI    BLTF96  DLS_02    DLS_03  \\\n",
       "0    0.273913  0.388889  0.326087  ...  0.755139  0.586207    0.83  0.746269   \n",
       "1    0.260870  0.333333  0.347826  ...  0.786416  0.489144    1.00  1.000000   \n",
       "2    0.260870  0.444444  0.217391  ...  0.791778  0.176245    0.83  1.000000   \n",
       "3    0.447826  0.000000  0.369565  ...  0.909741  0.252874    1.00  1.000000   \n",
       "4    0.447826  0.055556  0.369565  ...  0.914209  0.223499    1.00  1.000000   \n",
       "..        ...       ...       ...  ...       ...       ...     ...       ...   \n",
       "564  0.365217  0.333333  0.282609  ...  0.751564  0.687101    1.00  1.000000   \n",
       "565  0.317391  0.111111  0.326087  ...  0.914209  0.249042    1.00  1.000000   \n",
       "566  0.417391  0.222222  0.347826  ...  0.893655  0.365262    1.00  1.000000   \n",
       "567  0.347826  0.444444  0.086957  ...  0.687221  0.825032    0.67  0.746269   \n",
       "568  0.617391  0.055556  0.239130  ...  0.940125  0.438059    0.67  0.746269   \n",
       "\n",
       "       DLS_04   DLS_06  DLS_cons  LLS_01    LLS_02  Class  \n",
       "0    0.666667  0.60241  0.530120    0.17  0.809524      0  \n",
       "1    0.555556  1.00000  0.759036    0.33  1.000000      1  \n",
       "2    1.000000  1.00000  0.927711    0.17  0.809524      2  \n",
       "3    0.555556  1.00000  0.843373    0.67  1.000000      2  \n",
       "4    0.555556  1.00000  0.710843    0.83  1.000000      2  \n",
       "..        ...      ...       ...     ...       ...    ...  \n",
       "564  0.333333  1.00000  0.722892    0.33  1.000000      2  \n",
       "565  0.777778  1.00000  0.879518    0.33  1.000000      1  \n",
       "566  0.777778  1.00000  0.879518    1.00  1.000000      0  \n",
       "567  0.888889  0.60241  0.662651    0.33  0.603175      2  \n",
       "568  0.777778  1.00000  0.795181    1.00  1.000000      0  \n",
       "\n",
       "[569 rows x 738 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trf=new_df.drop('Class',axis=1)\n",
    "y_trf=new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=30\n",
    "features_chi2=SelectKBest(chi2, k=k)\n",
    "x_new=features_chi2.fit_transform(x_trf,y_trf)\n",
    "selected_features=df.columns[:-1][features_chi2.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nF', 'nX', 'P_VSA_ppp_hal', 'SM03_EA(dm)', 'nR=Cs', 'nR=Ct', 'C-005', 'C-006', 'C-016', 'H-053', 'O-060', 'SdsCH', 'CATS2D_04_DD', 'CATS2D_04_DA', 'CATS2D_05_DA', 'CATS2D_07_DL', 'CATS2D_03_PL', 'T(O..F)', 'T(F..F)', 'F03[C-S]', 'F04[N-Cl]', 'F05[C-S]', 'F05[N-N]', 'F05[N-F]', 'F06[C-F]', 'F07[C-F]', 'F07[C-Br]', 'F09[C-F]', 'F09[N-F]', 'F10[C-F]']\n"
     ]
    }
   ],
   "source": [
    "print(selected_features.to_list())\n",
    "final_df=df[selected_features.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\AppData\\Local\\Temp\\ipykernel_17988\\3084608001.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['Class']=df['Class']\n"
     ]
    }
   ],
   "source": [
    "final_df['Class']=df['Class']\n",
    "m=final_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final=new_df.drop(\"Class\",axis=1)\n",
    "y_final=new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class           1.000000\n",
       "C-005           0.332119\n",
       "C-016           0.311954\n",
       "MATS2p          0.299658\n",
       "MATS2i          0.280997\n",
       "GATS2i          0.278562\n",
       "SdsCH           0.266876\n",
       "GATS2p          0.262576\n",
       "CATS2D_04_DA    0.256093\n",
       "PCR             0.248253\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(new_df.corr(method='pearson')['Class']).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=RandomForestClassifier()\n",
    "clf2=LogisticRegression()\n",
    "clf3=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('RF', clf1),  # Include the first classifier (Logistic Regression)\n",
    "          # Include the second classifier (Random Forest)\n",
    "        ('GBC', clf3),  # Include the third classifier (Naive Bayes)\n",
    "    ],\n",
    "    voting='hard'  # Specify hard voting, where the majority class prediction is chosen\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6575738916256159"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf1,x_final,y_final,cv=20,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nF</th>\n",
       "      <th>nX</th>\n",
       "      <th>P_VSA_ppp_hal</th>\n",
       "      <th>SM03_EA(dm)</th>\n",
       "      <th>nR=Cs</th>\n",
       "      <th>nR=Ct</th>\n",
       "      <th>C-005</th>\n",
       "      <th>C-006</th>\n",
       "      <th>C-016</th>\n",
       "      <th>H-053</th>\n",
       "      <th>...</th>\n",
       "      <th>F05[C-S]</th>\n",
       "      <th>F05[N-N]</th>\n",
       "      <th>F05[N-F]</th>\n",
       "      <th>F06[C-F]</th>\n",
       "      <th>F07[C-F]</th>\n",
       "      <th>F07[C-Br]</th>\n",
       "      <th>F09[C-F]</th>\n",
       "      <th>F09[N-F]</th>\n",
       "      <th>F10[C-F]</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.406857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.103392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.647198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nF        nX  P_VSA_ppp_hal  SM03_EA(dm)     nR=Cs     nR=Ct     C-005  \\\n",
       "0    0.0  0.000000           0.00     0.406857  0.333333  0.000000  0.000000   \n",
       "1    0.0  0.000000           0.00     0.000000  1.000000  0.000000  0.333333   \n",
       "2    0.0  0.000000           0.00     0.000000  0.666667  0.333333  0.000000   \n",
       "3    0.0  0.000000           0.00     0.000000  0.000000  0.000000  0.000000   \n",
       "4    0.0  0.166667           0.25     0.000000  0.000000  0.000000  0.000000   \n",
       "..   ...       ...            ...          ...       ...       ...       ...   \n",
       "564  0.0  0.000000           0.00     0.000000  0.000000  0.000000  0.000000   \n",
       "565  0.0  0.000000           0.00     0.146925  0.500000  0.000000  0.000000   \n",
       "566  0.0  0.000000           0.00     0.103392  0.000000  0.000000  0.666667   \n",
       "567  0.0  0.000000           0.00     0.647198  0.000000  0.000000  0.000000   \n",
       "568  0.0  0.000000           0.00     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        C-006     C-016  H-053  ...  F05[C-S]  F05[N-N]  F05[N-F]  F06[C-F]  \\\n",
       "0    0.000000  0.333333    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "1    0.000000  0.833333    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "2    0.000000  0.666667    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "3    0.066667  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "4    0.066667  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "..        ...       ...    ...  ...       ...       ...       ...       ...   \n",
       "564  0.000000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "565  0.133333  0.500000    0.0  ...  0.181818       0.0       0.0       0.0   \n",
       "566  0.000000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "567  0.400000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "568  0.000000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "\n",
       "     F07[C-F]  F07[C-Br]  F09[C-F]  F09[N-F]  F10[C-F]  Class  \n",
       "0         0.0        0.0       0.0       0.0       0.0      0  \n",
       "1         0.0        0.0       0.0       0.0       0.0      1  \n",
       "2         0.0        0.0       0.0       0.0       0.0      2  \n",
       "3         0.0        0.0       0.0       0.0       0.0      2  \n",
       "4         0.0        0.0       0.0       0.0       0.0      2  \n",
       "..        ...        ...       ...       ...       ...    ...  \n",
       "564       0.0        0.0       0.0       0.0       0.0      2  \n",
       "565       0.0        0.0       0.0       0.0       0.0      1  \n",
       "566       0.0        0.0       0.0       0.0       0.0      0  \n",
       "567       0.0        0.0       0.0       0.0       0.0      2  \n",
       "568       0.0        0.0       0.0       0.0       0.0      0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[final_df.columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df=df[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nF</th>\n",
       "      <th>nX</th>\n",
       "      <th>P_VSA_ppp_hal</th>\n",
       "      <th>SM03_EA(dm)</th>\n",
       "      <th>nR=Cs</th>\n",
       "      <th>nR=Ct</th>\n",
       "      <th>C-005</th>\n",
       "      <th>C-006</th>\n",
       "      <th>C-016</th>\n",
       "      <th>H-053</th>\n",
       "      <th>...</th>\n",
       "      <th>F05[C-S]</th>\n",
       "      <th>F05[N-N]</th>\n",
       "      <th>F05[N-F]</th>\n",
       "      <th>F06[C-F]</th>\n",
       "      <th>F07[C-F]</th>\n",
       "      <th>F07[C-Br]</th>\n",
       "      <th>F09[C-F]</th>\n",
       "      <th>F09[N-F]</th>\n",
       "      <th>F10[C-F]</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.810</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nF   nX  P_VSA_ppp_hal  SM03_EA(dm)  nR=Cs  nR=Ct  C-005  C-006  C-016  \\\n",
       "0    0.0  0.0           0.00        2.243    2.0    0.0    0.0    0.0    2.0   \n",
       "1    0.0  0.0           0.00        0.000    6.0    0.0    2.0    0.0    5.0   \n",
       "2    0.0  0.0           0.00        0.000    4.0    2.0    0.0    0.0    4.0   \n",
       "3    0.0  0.0           0.00        0.000    0.0    0.0    0.0    1.0    0.0   \n",
       "4    0.0  1.0          39.15        0.000    0.0    0.0    0.0    1.0    0.0   \n",
       "..   ...  ...            ...          ...    ...    ...    ...    ...    ...   \n",
       "564  0.0  0.0           0.00        0.000    0.0    0.0    0.0    0.0    0.0   \n",
       "565  0.0  0.0           0.00        0.810    3.0    0.0    0.0    2.0    3.0   \n",
       "566  0.0  0.0           0.00        0.570    0.0    0.0    4.0    0.0    0.0   \n",
       "567  0.0  0.0           0.00        3.568    0.0    0.0    0.0    6.0    0.0   \n",
       "568  0.0  0.0           0.00        0.000    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     H-053  ...  F05[C-S]  F05[N-N]  F05[N-F]  F06[C-F]  F07[C-F]  F07[C-Br]  \\\n",
       "0      0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "1      0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "2      0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "3      0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "4      0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "..     ...  ...       ...       ...       ...       ...       ...        ...   \n",
       "564    0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "565    0.0  ...       2.0       0.0       0.0       0.0       0.0        0.0   \n",
       "566    0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "567    0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "568    0.0  ...       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "\n",
       "     F09[C-F]  F09[N-F]  F10[C-F]  Class  \n",
       "0         0.0       0.0       0.0      0  \n",
       "1         0.0       0.0       0.0      1  \n",
       "2         0.0       0.0       0.0      2  \n",
       "3         0.0       0.0       0.0      2  \n",
       "4         0.0       0.0       0.0      2  \n",
       "..        ...       ...       ...    ...  \n",
       "564       0.0       0.0       0.0      2  \n",
       "565       0.0       0.0       0.0      1  \n",
       "566       0.0       0.0       0.0      0  \n",
       "567       0.0       0.0       0.0      2  \n",
       "568       0.0       0.0       0.0      0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trf=one_df.drop('Class',axis=1)\n",
    "y_trf=one_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trf=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpDiam_AEA(bo)    0.214969\n",
       "CATS2D_04_DD      0.222797\n",
       "SssCH2            0.226765\n",
       "GATS2i            0.228884\n",
       "Chi1_EA(dm)       0.229526\n",
       "GATS2p            0.231268\n",
       "MCD               0.231931\n",
       "F03[N-N]          0.233445\n",
       "CATS2D_04_DA      0.293005\n",
       "Class             1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.corr(method='spearman')['Class'].sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_values, p_values = chi2(x_trf, y_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_df = pd.DataFrame({\n",
    "    'Feature': x_trf.columns,\n",
    "    'Chi2 Value': chi2_values,\n",
    "    'P-Value': p_values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=chi2_df['Chi2 Value'].sort_values(ascending=False).head(20).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    16706.425783\n",
       "18     4828.034718\n",
       "2       998.596475\n",
       "24      238.394261\n",
       "29      176.513047\n",
       "7       138.028873\n",
       "11      121.211799\n",
       "6       105.957106\n",
       "8        92.854008\n",
       "25       91.630080\n",
       "13       89.496266\n",
       "14       86.007566\n",
       "15       84.314319\n",
       "21       74.609872\n",
       "0        70.485640\n",
       "27       69.809292\n",
       "9        66.903862\n",
       "1        64.263012\n",
       "19       63.942203\n",
       "28       62.521004\n",
       "Name: Chi2 Value, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_df['Chi2 Value'].sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=chi2_df['P-Value']<=0.05\n",
    "mask2=chi2_df['Chi2 Value']>=9.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=chi2_df[mask1&mask2]['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nF',\n",
       " 'nX',\n",
       " 'P_VSA_ppp_hal',\n",
       " 'SM03_EA(dm)',\n",
       " 'nR=Cs',\n",
       " 'nR=Ct',\n",
       " 'C-005',\n",
       " 'C-006',\n",
       " 'C-016',\n",
       " 'H-053',\n",
       " 'O-060',\n",
       " 'SdsCH',\n",
       " 'CATS2D_04_DD',\n",
       " 'CATS2D_04_DA',\n",
       " 'CATS2D_05_DA',\n",
       " 'CATS2D_07_DL',\n",
       " 'CATS2D_03_PL',\n",
       " 'T(O..F)',\n",
       " 'T(F..F)',\n",
       " 'F03[C-S]',\n",
       " 'F04[N-Cl]',\n",
       " 'F05[C-S]',\n",
       " 'F05[N-N]',\n",
       " 'F05[N-F]',\n",
       " 'F06[C-F]',\n",
       " 'F07[C-F]',\n",
       " 'F07[C-Br]',\n",
       " 'F09[C-F]',\n",
       " 'F09[N-F]',\n",
       " 'F10[C-F]']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nF',\n",
       " 'nX',\n",
       " 'P_VSA_ppp_hal',\n",
       " 'SM03_EA(dm)',\n",
       " 'nR=Cs',\n",
       " 'nR=Ct',\n",
       " 'C-005',\n",
       " 'C-006',\n",
       " 'C-016',\n",
       " 'H-053',\n",
       " 'O-060',\n",
       " 'SdsCH',\n",
       " 'CATS2D_04_DD',\n",
       " 'CATS2D_04_DA',\n",
       " 'CATS2D_05_DA',\n",
       " 'CATS2D_07_DL',\n",
       " 'CATS2D_03_PL',\n",
       " 'T(O..F)',\n",
       " 'T(F..F)',\n",
       " 'F03[C-S]',\n",
       " 'F04[N-Cl]',\n",
       " 'F05[C-S]',\n",
       " 'F05[N-N]',\n",
       " 'F05[N-F]',\n",
       " 'F06[C-F]',\n",
       " 'F07[C-F]',\n",
       " 'F07[C-Br]',\n",
       " 'F09[C-F]',\n",
       " 'F09[N-F]',\n",
       " 'F10[C-F]']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=chi2_df[mask1&mask2]['Feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=new_df[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\AppData\\Local\\Temp\\ipykernel_17988\\695168134.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['Class']=new_df['Class']\n"
     ]
    }
   ],
   "source": [
    "final_df['Class']=new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=new_df.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73815987933635, 0.7010935143288084, 0.652526395173454, 0.582051282051282]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trf,x_test_trf,y_train_trf,y_test_trf=train_test_split(x_trf,y_trf,random_state=42,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst.append(np.mean(cross_val_score(clf1,x_train_trf,y_train_trf,cv=10,scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(x_train_trf,y_train_trf)\n",
    "y_pred=clf1.predict(x_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=GradientBoostingClassifier()\n",
    "clf3=LogisticRegression()\n",
    "clf4=AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lst.append(np.mean(cross_val_score(clf2,x_train_trf,y_train_trf,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf3,x_train_trf,y_train_trf,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf4,x_train_trf,y_train_trf,cv=10,scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3508771929824561"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5552318295739348"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf2,x_trf,y_trf,cv=10,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7246983408748114"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf1,x_train_trf,y_train_trf,cv=10,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf4=SVC()\n",
    "clf5=AdaBoostClassifier()\n",
    "clf6=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(clf,x_train_trf,y_train_trf,cv=10,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>GD</th>\n",
       "      <th>nTA</th>\n",
       "      <th>nBM</th>\n",
       "      <th>...</th>\n",
       "      <th>ALOGP2</th>\n",
       "      <th>PDI</th>\n",
       "      <th>BLTF96</th>\n",
       "      <th>DLS_02</th>\n",
       "      <th>DLS_03</th>\n",
       "      <th>DLS_04</th>\n",
       "      <th>DLS_06</th>\n",
       "      <th>DLS_cons</th>\n",
       "      <th>LLS_01</th>\n",
       "      <th>LLS_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.317645</td>\n",
       "      <td>0.281847</td>\n",
       "      <td>0.340455</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.424069</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116478</td>\n",
       "      <td>0.852547</td>\n",
       "      <td>0.560664</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.190773</td>\n",
       "      <td>0.216472</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.839352</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.389685</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076418</td>\n",
       "      <td>0.837355</td>\n",
       "      <td>0.357599</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.498603</td>\n",
       "      <td>0.123408</td>\n",
       "      <td>0.541288</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>0.277937</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099408</td>\n",
       "      <td>0.863271</td>\n",
       "      <td>0.269476</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.346515</td>\n",
       "      <td>0.095276</td>\n",
       "      <td>0.404848</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>0.217765</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.126087</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076813</td>\n",
       "      <td>0.815907</td>\n",
       "      <td>0.394636</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.162906</td>\n",
       "      <td>0.144639</td>\n",
       "      <td>0.227727</td>\n",
       "      <td>0.779577</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.297994</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.904379</td>\n",
       "      <td>0.395913</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.180027</td>\n",
       "      <td>0.218861</td>\n",
       "      <td>0.234242</td>\n",
       "      <td>0.836862</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.386819</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034484</td>\n",
       "      <td>0.939231</td>\n",
       "      <td>0.438059</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.162118</td>\n",
       "      <td>0.185686</td>\n",
       "      <td>0.222879</td>\n",
       "      <td>0.814446</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.352436</td>\n",
       "      <td>0.406977</td>\n",
       "      <td>0.286957</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.854334</td>\n",
       "      <td>0.335888</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.181603</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.256970</td>\n",
       "      <td>0.754670</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.275072</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085298</td>\n",
       "      <td>0.869526</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.147647</td>\n",
       "      <td>0.381281</td>\n",
       "      <td>0.172348</td>\n",
       "      <td>0.858032</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.512894</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072817</td>\n",
       "      <td>0.924933</td>\n",
       "      <td>0.224777</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.207321</td>\n",
       "      <td>0.214260</td>\n",
       "      <td>0.262424</td>\n",
       "      <td>0.845579</td>\n",
       "      <td>0.311321</td>\n",
       "      <td>0.418338</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>0.916890</td>\n",
       "      <td>0.409962</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MW       AMW        Sv        Mv        Me        Mp        Mi  \\\n",
       "204  0.317645  0.281847  0.340455  0.874222  0.518868  0.424069  0.209302   \n",
       "70   0.190773  0.216472  0.245000  0.839352  0.358491  0.389685  0.279070   \n",
       "131  0.498603  0.123408  0.541288  0.767123  0.216981  0.277937  0.534884   \n",
       "431  0.346515  0.095276  0.404848  0.739726  0.216981  0.217765  0.546512   \n",
       "540  0.162906  0.144639  0.227727  0.779577  0.226415  0.297994  0.581395   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "486  0.180027  0.218861  0.234242  0.836862  0.339623  0.386819  0.395349   \n",
       "75   0.162118  0.185686  0.222879  0.814446  0.301887  0.352436  0.406977   \n",
       "249  0.181603  0.093595  0.256970  0.754670  0.113208  0.275072  0.569767   \n",
       "238  0.147647  0.381281  0.172348  0.858032  0.245283  0.512894  0.383721   \n",
       "265  0.207321  0.214260  0.262424  0.845579  0.311321  0.418338  0.267442   \n",
       "\n",
       "           GD       nTA       nBM  ...    ALOGP2       PDI    BLTF96  DLS_02  \\\n",
       "204  0.152174  0.444444  0.608696  ...  0.116478  0.852547  0.560664    0.50   \n",
       "70   0.243478  0.277778  0.456522  ...  0.076418  0.837355  0.357599    1.00   \n",
       "131  0.069565  0.444444  0.652174  ...  0.099408  0.863271  0.269476    0.33   \n",
       "431  0.126087  0.444444  0.434783  ...  0.076813  0.815907  0.394636    0.50   \n",
       "540  0.300000  0.055556  0.369565  ...  0.018298  0.904379  0.395913    1.00   \n",
       "..        ...       ...       ...  ...       ...       ...       ...     ...   \n",
       "486  0.282609  0.166667  0.413043  ...  0.034484  0.939231  0.438059    1.00   \n",
       "75   0.286957  0.222222  0.347826  ...  0.020799  0.854334  0.335888    1.00   \n",
       "249  0.256522  0.055556  0.391304  ...  0.085298  0.869526  0.264368    0.83   \n",
       "238  0.417391  0.111111  0.369565  ...  0.072817  0.924933  0.224777    1.00   \n",
       "265  0.239130  0.166667  0.456522  ...  0.066650  0.916890  0.409962    1.00   \n",
       "\n",
       "       DLS_03    DLS_04    DLS_06  DLS_cons  LLS_01    LLS_02  \n",
       "204  0.746269  0.222222  0.602410  0.409639    0.17  0.396825  \n",
       "70   1.000000  0.555556  1.000000  0.759036    0.33  1.000000  \n",
       "131  0.253731  0.777778  0.192771  0.397590    0.00  0.000000  \n",
       "431  0.507463  0.888889  0.602410  0.650602    0.17  0.396825  \n",
       "540  1.000000  0.777778  1.000000  0.879518    0.33  1.000000  \n",
       "..        ...       ...       ...       ...     ...       ...  \n",
       "486  1.000000  0.555556  1.000000  0.843373    0.50  0.809524  \n",
       "75   1.000000  0.555556  1.000000  0.759036    0.17  1.000000  \n",
       "249  0.746269  1.000000  0.795181  0.746988    0.17  0.809524  \n",
       "238  1.000000  0.555556  1.000000  0.710843    0.33  1.000000  \n",
       "265  1.000000  0.555556  1.000000  0.843373    0.50  0.809524  \n",
       "\n",
       "[114 rows x 737 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df=pd.concat([x_train_trf,x_test_trf],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df=new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_df=pd.concat([x_df,y_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_df.to_csv('for_regression1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.50      0.57      0.53        14\\n           1       0.47      0.54      0.50        13\\n           2       0.96      0.83      0.89        30\\n\\n    accuracy                           0.70        57\\n   macro avg       0.64      0.65      0.64        57\\nweighted avg       0.74      0.70      0.71        57\\n'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_pred,y_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  5,  2],\n",
       "       [ 4,  3,  7],\n",
       "       [ 3,  5, 20]], dtype=int64)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_trf,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47846978638064225"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_test_trf,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_df=pd.DataFrame(columns=['Mod','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_df['Mod']=['RandomForestClassifier','GradientBoostingClassifier','LogisticRegression','AdaBoostClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_df['Accuracy']=lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mod</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.738160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.701094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.652526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.582051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Mod  Accuracy\n",
       "0      RandomForestClassifier  0.738160\n",
       "1  GradientBoostingClassifier  0.701094\n",
       "2          LogisticRegression  0.652526\n",
       "3          AdaBoostClassifier  0.582051"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# Assuming 'plotting' is a dictionary with 'Mod' and 'Accuracy' columns\n",
    "\n",
    "# Define a color list\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange','violet']  # Adjust colors and length as needed\n",
    "\n",
    "# Create the bar plot with custom colors\n",
    "plt.bar(x=plotting_df['Mod'], height=plotting_df['Accuracy'], color=colors[:len(plotting_df['Mod'])])\n",
    "\n",
    "# Rotate x-axis labels (optional)\n",
    "plt.xticks(rotation='vertical')  \n",
    "for i, (v, label) in enumerate(zip(plotting_df['Accuracy'], plotting_df['Mod'])):\n",
    "  y_pos = v + 0.01  # Adjust y position for label placement\n",
    "  plt.text(i, y_pos, f\"{v:.2f}\", ha='center')  # Format accuracy with 2 decimal places\n",
    "\n",
    "\n",
    "# Add accuracy labels using plt.text (optional)\n",
    "# ... (code for adding accuracy labels remains the same)\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy by Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17988\\2950344198.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train_trf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6293\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6294\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akshat\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-13 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-13 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-13 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-13 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-13 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-13 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-13 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-13 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-13 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(x_train_trf,y_train_trf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf4.predict(x_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5964912280701754"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  4,  3],\n",
       "       [ 4,  4,  7],\n",
       "       [ 3,  2, 21]], dtype=int64)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_trf,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2\n",
       "0  9  4   3\n",
       "1  4  4   7\n",
       "2  3  2  21"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test_trf,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.56      0.56      0.56        16\\n           1       0.27      0.40      0.32        10\\n           2       0.81      0.68      0.74        31\\n\\n    accuracy                           0.60        57\\n   macro avg       0.55      0.55      0.54        57\\nweighted avg       0.64      0.60      0.61        57\\n'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_pred, y_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
