{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Compiled_descriptors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Class',axis=1)\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=MinMaxScaler((0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data=scalar.fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame(scaled_data, columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Class']=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df['Class'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\akshat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\akshat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\akshat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\akshat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\akshat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=new_df.drop('Class',axis=1)\n",
    "y=new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_values, p_values = chi2(new_df.drop('Class', axis=1), new_df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_df = pd.DataFrame({\n",
    "    'Feature': new_df.drop('Class', axis=1).columns,\n",
    "    'Chi2 Value': chi2_values,\n",
    "    'P-Value': p_values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Chi2 Value</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MW</td>\n",
       "      <td>0.404383</td>\n",
       "      <td>0.816939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMW</td>\n",
       "      <td>2.765649</td>\n",
       "      <td>0.250869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sv</td>\n",
       "      <td>0.305823</td>\n",
       "      <td>0.858206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mv</td>\n",
       "      <td>0.488554</td>\n",
       "      <td>0.783271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me</td>\n",
       "      <td>3.560913</td>\n",
       "      <td>0.168561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>DLS_04</td>\n",
       "      <td>1.960932</td>\n",
       "      <td>0.375136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>DLS_06</td>\n",
       "      <td>0.587180</td>\n",
       "      <td>0.745582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>DLS_cons</td>\n",
       "      <td>0.276097</td>\n",
       "      <td>0.871057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>LLS_01</td>\n",
       "      <td>0.745120</td>\n",
       "      <td>0.688968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>LLS_02</td>\n",
       "      <td>1.247056</td>\n",
       "      <td>0.536050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Chi2 Value   P-Value\n",
       "0          MW    0.404383  0.816939\n",
       "1         AMW    2.765649  0.250869\n",
       "2          Sv    0.305823  0.858206\n",
       "3          Mv    0.488554  0.783271\n",
       "4          Me    3.560913  0.168561\n",
       "..        ...         ...       ...\n",
       "732    DLS_04    1.960932  0.375136\n",
       "733    DLS_06    0.587180  0.745582\n",
       "734  DLS_cons    0.276097  0.871057\n",
       "735    LLS_01    0.745120  0.688968\n",
       "736    LLS_02    1.247056  0.536050\n",
       "\n",
       "[737 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=chi2_df['P-Value']<=0.05\n",
    "mask2=chi2_df['Chi2 Value']>=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=chi2_df[mask1&mask2]['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=new_df[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\AppData\\Local\\Temp\\ipykernel_3636\\695168134.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['Class']=new_df['Class']\n"
     ]
    }
   ],
   "source": [
    "final_df['Class']=new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nF</th>\n",
       "      <th>nX</th>\n",
       "      <th>P_VSA_ppp_hal</th>\n",
       "      <th>SM03_EA(dm)</th>\n",
       "      <th>nR=Cs</th>\n",
       "      <th>nR=Ct</th>\n",
       "      <th>C-005</th>\n",
       "      <th>C-006</th>\n",
       "      <th>C-016</th>\n",
       "      <th>H-053</th>\n",
       "      <th>...</th>\n",
       "      <th>F05[C-S]</th>\n",
       "      <th>F05[N-N]</th>\n",
       "      <th>F05[N-F]</th>\n",
       "      <th>F06[C-F]</th>\n",
       "      <th>F07[C-F]</th>\n",
       "      <th>F07[C-Br]</th>\n",
       "      <th>F09[C-F]</th>\n",
       "      <th>F09[N-F]</th>\n",
       "      <th>F10[C-F]</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.627426</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587702</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.588790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nF        nX  P_VSA_ppp_hal  SM03_EA(dm)     nR=Cs     nR=Ct     C-005  \\\n",
       "0    0.0  0.000000            0.0     1.627426  1.333333  0.000000  0.000000   \n",
       "1    0.0  0.000000            0.0     0.000000  4.000000  0.000000  1.333333   \n",
       "2    0.0  0.000000            0.0     0.000000  2.666667  1.333333  0.000000   \n",
       "3    0.0  0.000000            0.0     0.000000  0.000000  0.000000  0.000000   \n",
       "4    0.0  0.666667            1.0     0.000000  0.000000  0.000000  0.000000   \n",
       "..   ...       ...            ...          ...       ...       ...       ...   \n",
       "564  0.0  0.000000            0.0     0.000000  0.000000  0.000000  0.000000   \n",
       "565  0.0  0.000000            0.0     0.587702  2.000000  0.000000  0.000000   \n",
       "566  0.0  0.000000            0.0     0.413568  0.000000  0.000000  2.666667   \n",
       "567  0.0  0.000000            0.0     2.588790  0.000000  0.000000  0.000000   \n",
       "568  0.0  0.000000            0.0     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        C-006     C-016  H-053  ...  F05[C-S]  F05[N-N]  F05[N-F]  F06[C-F]  \\\n",
       "0    0.000000  1.333333    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "1    0.000000  3.333333    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "2    0.000000  2.666667    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "3    0.266667  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "4    0.266667  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "..        ...       ...    ...  ...       ...       ...       ...       ...   \n",
       "564  0.000000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "565  0.533333  2.000000    0.0  ...  0.727273       0.0       0.0       0.0   \n",
       "566  0.000000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "567  1.600000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "568  0.000000  0.000000    0.0  ...  0.000000       0.0       0.0       0.0   \n",
       "\n",
       "     F07[C-F]  F07[C-Br]  F09[C-F]  F09[N-F]  F10[C-F]  Class  \n",
       "0         0.0        0.0       0.0       0.0       0.0      0  \n",
       "1         0.0        0.0       0.0       0.0       0.0      1  \n",
       "2         0.0        0.0       0.0       0.0       0.0      2  \n",
       "3         0.0        0.0       0.0       0.0       0.0      2  \n",
       "4         0.0        0.0       0.0       0.0       0.0      2  \n",
       "..        ...        ...       ...       ...       ...    ...  \n",
       "564       0.0        0.0       0.0       0.0       0.0      2  \n",
       "565       0.0        0.0       0.0       0.0       0.0      1  \n",
       "566       0.0        0.0       0.0       0.0       0.0      0  \n",
       "567       0.0        0.0       0.0       0.0       0.0      2  \n",
       "568       0.0        0.0       0.0       0.0       0.0      0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=final_df.drop('Class',axis=1)\n",
    "y=final_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw={}\n",
    "clf1=RandomForestClassifier(n_estimators=1000, n_jobs=1, bootstrap=False, max_depth=70)\n",
    "clf2=GradientBoostingClassifier(n_estimators=500)\n",
    "clf3=LogisticRegression(max_iter=4500)\n",
    "clf4=AdaBoostClassifier(n_estimators=500)\n",
    "clf5=SVC(probability = True, max_iter = 2000, class_weight = cw)\n",
    "clf6=KNeighborsClassifier(n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Akshat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lst.append(np.mean(cross_val_score(clf1,x_train_smote,y_train_smote,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf2,x_train_smote,y_train_smote,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf3,x_train_smote,y_train_smote,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf4,x_train_smote,y_train_smote,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf5,x_train_smote,y_train_smote,cv=10,scoring='accuracy')))\n",
    "lst.append(np.mean(cross_val_score(clf6,x_train_smote,y_train_smote,cv=10,scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8062233589087808,\n",
       " 0.7797527706734868,\n",
       " 0.5962063086104006,\n",
       " 0.5801364023870417,\n",
       " 0.652003410059676,\n",
       " 0.6432438192668373]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
